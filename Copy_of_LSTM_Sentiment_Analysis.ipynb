{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP5M6mEmDg7gAUX+WfBgZiD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sana0409-ai/LSTM-based-Stock-Sentiment-Analysis-with-Multi-Source-Data/blob/main/Copy_of_LSTM_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ze5yrEnKf7cB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary libraries\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import List, Optional, Tuple, Dict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "!pip install -q pandas numpy sentence-transformers\n",
        "import torch\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "# Importing the 'nn' module, which provides tools to build neural networks (e.g., layers, loss functions)\n",
        "import torch.nn as nn\n",
        "\n",
        "# Importing functional API from 'nn', which gives access to activation functions and other operations\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Importing everything from torch.utils.data (e.g., Dataset, DataLoader, random_split)\n",
        "# These are used for handling datasets and batching\n",
        "from torch.utils.data import *\n",
        "\n",
        "from sklearn.metrics import accuracy_score  # Measures the proportion of correct predictions\n",
        "\n",
        "# Importing Python's built-in time module\n",
        "# Provides tools for measuring execution time, delaying execution, and working with timestamps\n",
        "import time\n",
        "\n",
        "# Importing tqdm for showing progress bars in loops (autonotebook works well in Jupyter)\n",
        "# tqdm.autonotebook can give a warning about experimental use.\n",
        "# To remove the warning, you can replace:\n",
        "# from tqdm.autonotebook import tqdm\n",
        "# with:\n",
        "# from tqdm import tqdm  # for console mode\n",
        "# or:\n",
        "# from tqdm.notebook import tqdm  # for Jupyter notebooks\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import RobustScaler # used for scaling\n",
        "from sklearn.model_selection import StratifiedShuffleSplit # This helps to split test and train to ensure consistent label distribution\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split #This helps to split test and train\n",
        "from sklearn.metrics import classification_report # This helps in building classification report\n",
        "\n",
        "\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "QVeX5l12g5fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading all files\n",
        "\n",
        "OHLCV_PATH = \"/content/drive/My Drive/Colab Notebooks/ohlcv_LSTM.csv\"\n",
        "\n",
        "SENTIMENT_PATHS = [\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Final data_polygonIO_finbert_av5 (1).csv\",\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Final data_tws_finbert_av5.csv\",\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Final data_Alpha_Vantage.csv\",\n",
        "]\n"
      ],
      "metadata": {
        "id": "C3Dd5eu2g8Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All sentiment and ohlcv data is aggregated into hourly buckets\n",
        "# Each sample is trained for past 48hrs of history in real time\n",
        "# the model looks 4hrs into future from current point to compute the label and if price after 4hrs is higher its bullish else bearish\n",
        "\n",
        "\n",
        "HOUR = \"1H\"            # hourly aggregation\n",
        "WINDOW = 48            # lookback window (48 hours)\n",
        "HORIZON_HOURS = 4      # bullish/bearish label uses 4h-ahead return\n",
        "NEUTRAL_SENTIMENT = 0.0 # when no sentiment data exists for that hour\n",
        "\n",
        "FEATURE_COLS = [\"close\", \"volume\", \"sentiment_shifted\"]  # 3 channels LSTM will look into at each time step, sentiment_shifted is the sentiment score from previous hour\n",
        "OUT_DIR = Path(\"/content/lstm_ready\")"
      ],
      "metadata": {
        "id": "MUDBSI0Tg_q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This helps with the column naming conventions which are case sensitive\n",
        "\n",
        "def find_first(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "        for col in df.columns:\n",
        "            if col.lower() == c.lower():\n",
        "                return col\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "3WfjGf5JhaMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV loader\n",
        "\n",
        "def load_any_csv(path: str) -> pd.DataFrame:\n",
        "    try:\n",
        "        return pd.read_csv(path)\n",
        "    except Exception:\n",
        "        try:\n",
        "            return pd.read_csv(path, encoding=\"latin-1\")\n",
        "        except Exception:\n",
        "            return pd.DataFrame()\n"
      ],
      "metadata": {
        "id": "MXTlzLeLhcVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finds the list of all datetime columns and converts them to standard UTC timezone\n",
        "def coerce_datetime_col(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:\n",
        "    col = find_first(df, candidates)\n",
        "    if col is None:\n",
        "        return None\n",
        "    if col == \"time_published\":  #\n",
        "        df[col] = pd.to_datetime(df[col], format=\"%Y%m%dT%H%M%S\", utc=True, errors=\"coerce\")\n",
        "    else:\n",
        "        df[col] = pd.to_datetime(df[col], utc=True, errors=\"coerce\")\n",
        "    return col\n"
      ],
      "metadata": {
        "id": "MeBQ9kd9hfW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixes the identifier column and standardizes its name to 'symbol'\n",
        "def standardize_symbol(df: pd.DataFrame) -> Optional[str]:\n",
        "    # include 'tickr' and common variants\n",
        "    sym = find_first(df, [\"tickr\", \"Ticker\", \"ticker\", \"symbol\", \"YahooSymbol\", \"Symbol\"])\n",
        "    if sym is None:\n",
        "        return None\n",
        "\n",
        "    # clean whitespace and empty strings\n",
        "    df[sym] = df[sym].astype(str).str.strip()\n",
        "    df.loc[df[sym].eq(\"\"), sym] = pd.NA\n",
        "\n",
        "    # standardize the column name used downstream\n",
        "    if sym != \"symbol\":\n",
        "        df.rename(columns={sym: \"symbol\"}, inplace=True)\n",
        "        sym = \"symbol\"\n",
        "\n",
        "    return sym\n"
      ],
      "metadata": {
        "id": "m9bLBtbthipB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding name of the column that contains the sentiment score and returns the name\n",
        "\n",
        "def detect_sentiment_score(df: pd.DataFrame) -> Optional[str]:\n",
        "    return find_first(df, [\"overall_score\", \"sentiment_score\", \"finbert_score\", \"score\", \"compound\"])\n"
      ],
      "metadata": {
        "id": "EWMrlhiPhk3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resampling the data frame to 1H buckets\n",
        "\n",
        "def to_hourly_fill(df: pd.DataFrame, time_col: str, agg: Dict[str, str], group_col: Optional[str]) -> pd.DataFrame:\n",
        "    if group_col and group_col in df.columns:\n",
        "        parts = []\n",
        "        for sym, g in df.groupby(group_col):\n",
        "            g = g.set_index(time_col).sort_index()\n",
        "            h = g.resample(HOUR).agg(agg)\n",
        "            h[group_col] = sym\n",
        "            parts.append(h.reset_index())\n",
        "        return pd.concat(parts, ignore_index=True) if parts else pd.DataFrame()\n",
        "    else:\n",
        "        return df.set_index(time_col).sort_index().resample(HOUR).agg(agg).reset_index()\n"
      ],
      "metadata": {
        "id": "bzlKrk3shnDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_hourly_sentiment(paths: List[str]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load multiple sentiment CSVs, convert to hourly means per (symbol, hour),\n",
        "    average across sources, fill missing hours with 0.0, and shift forward by 1 hour\n",
        "    to avoid look-ahead.\n",
        "    \"\"\"\n",
        "    frames = []\n",
        "    for p in paths:\n",
        "        df = load_any_csv(p)  # read each CSV\n",
        "        if df.empty:\n",
        "            continue\n",
        "\n",
        "        # find/parse timestamp (handles Alpha Vantage 'time_published' specially)\n",
        "        time_col = coerce_datetime_col(\n",
        "            df,\n",
        "            [\"published_utc\", \"time_published\", \"datetime\", \"published_at\", \"created_at\",\n",
        "             \"date\", \"timestamp\", \"Datetime\", \"Date\", \"Time\", \"time\"]\n",
        "        )\n",
        "        if time_col is None:\n",
        "            continue\n",
        "\n",
        "        # find symbol + sentiment score columns\n",
        "        sym_col = standardize_symbol(df)  # may return None\n",
        "        score_col = detect_sentiment_score(df)\n",
        "        if score_col is None:\n",
        "            continue\n",
        "\n",
        "        # normalize column names\n",
        "        keep = [time_col, score_col] + ([sym_col] if sym_col else [])\n",
        "        sdf = df[keep].copy()\n",
        "\n",
        "        rename_map = {time_col: \"datetime\", score_col: \"sentiment_score\"}\n",
        "        if sym_col:\n",
        "            rename_map[sym_col] = \"symbol\"\n",
        "        sdf.rename(columns=rename_map, inplace=True)\n",
        "\n",
        "        # drop rows with bad datetimes\n",
        "        sdf = sdf.dropna(subset=[\"datetime\"])\n",
        "\n",
        "        # hourly mean sentiment (per symbol if present)\n",
        "        hourly = to_hourly_fill(\n",
        "            sdf,\n",
        "            time_col=\"datetime\",\n",
        "            agg={\"sentiment_score\": \"mean\"},\n",
        "            group_col=\"symbol\" if \"symbol\" in sdf.columns else None\n",
        "        )\n",
        "        hourly[\"sentiment_score\"] = hourly[\"sentiment_score\"].fillna(NEUTRAL_SENTIMENT)\n",
        "        frames.append(hourly)\n",
        "\n",
        "    # if nothing usable was found\n",
        "    if not frames:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # average across sources for the same (datetime, symbol?)\n",
        "    all_sent = pd.concat(frames, ignore_index=True)\n",
        "\n",
        "    group_cols = [\"datetime\"] + ([\"symbol\"] if \"symbol\" in all_sent.columns else [])\n",
        "    sent = (\n",
        "        all_sent\n",
        "        .groupby(group_cols, as_index=False, sort=True)[\"sentiment_score\"]\n",
        "        .mean()\n",
        "    )\n",
        "\n",
        "    # shift +1h so hour t uses info up to t-1\n",
        "    if \"symbol\" in sent.columns:\n",
        "        sent = sent.sort_values([\"symbol\", \"datetime\"])\n",
        "        sent[\"sentiment_shifted\"] = sent.groupby(\"symbol\")[\"sentiment_score\"].shift(1)\n",
        "    else:\n",
        "        sent = sent.sort_values([\"datetime\"])\n",
        "        sent[\"sentiment_shifted\"] = sent[\"sentiment_score\"].shift(1)\n",
        "\n",
        "    sent[\"sentiment_shifted\"] = sent[\"sentiment_shifted\"].fillna(NEUTRAL_SENTIMENT)\n",
        "    return sent\n"
      ],
      "metadata": {
        "id": "ZZ_6aLfxhpqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_hourly_ohlcv(\n",
        "    path: str,\n",
        "    restrict_rth: bool = True,\n",
        "    ffill_within_day: bool = True,\n",
        "    tz_local: str = \"America/New_York\",\n",
        ") -> pd.DataFrame:\n",
        "    df = load_any_csv(path)\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    # 1) Timestamp column\n",
        "    time_col = find_first(df, [\"Datetime_UTC\",\"Datetime_ET\",\"datetime\",\"timestamp\",\"date\",\n",
        "                               \"Datetime\",\"Date\",\"Time\",\"time\"])\n",
        "    if time_col is None:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # 2) Parse timestamps (handle tz-aware vs naive)\n",
        "    col_lower = time_col.lower()\n",
        "    s = pd.to_datetime(df[time_col], errors=\"coerce\")\n",
        "\n",
        "    if \"et\" in col_lower:  # local Eastern time\n",
        "        if s.dt.tz is None:\n",
        "            s = s.dt.tz_localize(tz_local, nonexistent=\"NaT\", ambiguous=\"NaT\")\n",
        "        else:\n",
        "            s = s.dt.tz_convert(tz_local)\n",
        "        s = s.dt.tz_convert(\"UTC\")  # normalize to UTC\n",
        "    else:  # assume already UTC or other tz → normalize to UTC\n",
        "        if s.dt.tz is None:\n",
        "            s = s.dt.tz_localize(\"UTC\")\n",
        "        else:\n",
        "            s = s.dt.tz_convert(\"UTC\")\n",
        "\n",
        "    df[time_col] = s\n",
        "    df = df.dropna(subset=[time_col])\n",
        "    if df.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # 3) Symbol (handles 'tickr' -> 'symbol')\n",
        "    sym_col = standardize_symbol(df)\n",
        "    if sym_col is None:\n",
        "        df[\"symbol\"] = \"UNKNOWN\"\n",
        "        sym_col = \"symbol\"\n",
        "\n",
        "    # 4) OHLCV columns\n",
        "    open_col  = find_first(df, [\"Open\",\"open\",\"o\"])\n",
        "    high_col  = find_first(df, [\"High\",\"high\",\"h\"])\n",
        "    low_col   = find_first(df, [\"Low\",\"low\",\"l\"])\n",
        "    close_col = find_first(df, [\"Close\",\"close\",\"Adj Close\",\"adj_close\",\"c\"])\n",
        "    vol_col   = find_first(df, [\"Volume\",\"volume\",\"vol\",\"v\"])\n",
        "\n",
        "    keep = [time_col, sym_col, open_col, high_col, low_col, close_col, vol_col]\n",
        "    keep = [k for k in keep if k is not None]\n",
        "    if len(keep) < 3:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    base = df[keep].copy()\n",
        "    base.columns = [\"datetime\",\"symbol\",\"open\",\"high\",\"low\",\"close\",\"volume\"][:len(base.columns)]\n",
        "    for c in [\"open\",\"high\",\"low\",\"close\",\"volume\"]:\n",
        "        if c in base.columns:\n",
        "            base[c] = pd.to_numeric(base[c], errors=\"coerce\")\n",
        "\n",
        "    # 5) Restrict to RTH (convert UTC→local to check hours)\n",
        "    if restrict_rth and not base.empty:\n",
        "        local = base[\"datetime\"].dt.tz_convert(tz_local)\n",
        "        is_rth = local.dt.time.between(pd.to_datetime(\"09:30\").time(),\n",
        "                                       pd.to_datetime(\"16:00\").time())\n",
        "        base = base[is_rth].copy()\n",
        "        if base.empty:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    # 6) Resample hourly per symbol\n",
        "    hourly = to_hourly_fill(\n",
        "        base, time_col=\"datetime\",\n",
        "        agg={\"open\":\"first\",\"high\":\"max\",\"low\":\"min\",\"close\":\"last\",\"volume\":\"sum\"},\n",
        "        group_col=\"symbol\"\n",
        "    )\n",
        "    if hourly.empty:\n",
        "        return hourly\n",
        "\n",
        "    # 7) Fill gaps\n",
        "    if \"volume\" in hourly.columns:\n",
        "        hourly[\"volume\"] = pd.to_numeric(hourly[\"volume\"], errors=\"coerce\").fillna(0)\n",
        "\n",
        "    price_cols = [c for c in [\"open\",\"high\",\"low\",\"close\"] if c in hourly.columns]\n",
        "    if price_cols:\n",
        "        if ffill_within_day:\n",
        "            local_h = hourly[\"datetime\"].dt.tz_convert(tz_local)\n",
        "            hourly[\"__local_date\"] = local_h.dt.date\n",
        "            hourly[price_cols] = (\n",
        "                hourly.sort_values([\"symbol\",\"datetime\"])\n",
        "                      .groupby([\"symbol\",\"__local_date\"])[price_cols]\n",
        "                      .ffill()\n",
        "            )\n",
        "            hourly.drop(columns=\"__local_date\", inplace=True)\n",
        "        else:\n",
        "            hourly[price_cols] = hourly[price_cols].ffill()\n",
        "\n",
        "    return hourly.sort_values([\"symbol\",\"datetime\"]).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "uir6C5OphscM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Join hourly OHLCV + hourly sentiment\n",
        "def join_features(ohlcv: pd.DataFrame, sent: pd.DataFrame) -> pd.DataFrame:\n",
        "    if ohlcv.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Ensure both frames have a common ID column named 'symbol'\n",
        "    if \"symbol\" not in ohlcv.columns and \"tickr\" in ohlcv.columns:\n",
        "        ohlcv = ohlcv.rename(columns={\"tickr\": \"symbol\"})\n",
        "    if not sent.empty:\n",
        "        if \"symbol\" not in sent.columns and \"tickr\" in sent.columns:\n",
        "            sent = sent.rename(columns={\"tickr\": \"symbol\"})\n",
        "\n",
        "    # If sentiment is empty or missing keys, just add neutral column\n",
        "    if sent.empty or not {\"datetime\",\"symbol\"}.issubset(sent.columns):\n",
        "        out = ohlcv.copy()\n",
        "        out[\"sentiment_shifted\"] = NEUTRAL_SENTIMENT\n",
        "        return out.sort_values([\"symbol\",\"datetime\"]).reset_index(drop=True)\n",
        "\n",
        "    # Merge on (datetime, symbol)\n",
        "    merged = pd.merge(\n",
        "        ohlcv,\n",
        "        sent[[\"datetime\",\"symbol\",\"sentiment_shifted\"]],\n",
        "        on=[\"datetime\",\"symbol\"],\n",
        "        how=\"left\"\n",
        "    )\n",
        "\n",
        "    merged[\"sentiment_shifted\"] = merged[\"sentiment_shifted\"].fillna(NEUTRAL_SENTIMENT)\n",
        "    return merged.sort_values([\"symbol\",\"datetime\"]).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "RyNBSj-thwIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_bullish_label(df: pd.DataFrame, horizon_hours: int) -> pd.DataFrame:\n",
        "    if df.empty:\n",
        "        return df\n",
        "    if \"close\" not in df.columns or \"datetime\" not in df.columns:\n",
        "        # cannot compute labels without these\n",
        "        return df\n",
        "\n",
        "    ret_col = f\"future_ret_{horizon_hours}h\"\n",
        "\n",
        "    def per_group(g: pd.DataFrame) -> pd.DataFrame:\n",
        "        g = g.sort_values(\"datetime\").copy()\n",
        "        # ensure numeric and avoid divide-by-zero\n",
        "        g[\"close\"] = pd.to_numeric(g[\"close\"], errors=\"coerce\")\n",
        "        g[\"future_close\"] = g[\"close\"].shift(-horizon_hours)             # t+H close\n",
        "        g.loc[g[\"close\"] == 0, \"close\"] = np.nan\n",
        "\n",
        "        # % return over the next H hours\n",
        "        g[ret_col] = (g[\"future_close\"] - g[\"close\"]) / g[\"close\"]\n",
        "\n",
        "        # 1 = Bullish if return > 0 else 0\n",
        "        g[\"target_updown\"] = (g[ret_col] > 0).astype(\"int8\")\n",
        "        return g\n",
        "\n",
        "    if \"symbol\" in df.columns:\n",
        "        out = df.groupby(\"symbol\", group_keys=False).apply(per_group)\n",
        "    else:\n",
        "        out = per_group(df)\n",
        "\n",
        "    # drop rows that don’t have the future price (last H bars per series)\n",
        "    out = out.dropna(subset=[ret_col, \"future_close\"]).reset_index(drop=True)\n",
        "\n",
        "    # keep compatibility with code that expects a fixed name\n",
        "    if horizon_hours == 4:\n",
        "        out[\"future_ret_4h\"] = out[ret_col]\n",
        "\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "iDzvAOqZhySP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transforming the data frames into stacked tensors as inputs for LSTM\n",
        "def make_windows(df: pd.DataFrame,\n",
        "                 window: int,\n",
        "                 features: List[str],\n",
        "                 cls_col: str,\n",
        "                 reg_col: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Build sliding windows for LSTM.\n",
        "    Returns:\n",
        "      X      : [N, window, F]\n",
        "      y_cls  : [N]    (0/1; 1=Bullish, 0=Bearish)\n",
        "      y_sent : [N]    (regression target; e.g., sentiment_shifted at time t)\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "\n",
        "    # Standardize ID column just in case\n",
        "    if \"symbol\" not in df.columns and \"tickr\" in df.columns:\n",
        "        df = df.rename(columns={\"tickr\": \"symbol\"})\n",
        "\n",
        "    # Keep only rows that have all needed columns\n",
        "    needed_cols = list(dict.fromkeys([\"symbol\", \"datetime\"] + features + [cls_col, reg_col]))\n",
        "    missing = [c for c in needed_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        # Return empty arrays if schema is missing (prevents crashes)\n",
        "        F = len(features)\n",
        "        return (np.empty((0, window, F), dtype=np.float32),\n",
        "                np.empty((0,), dtype=np.float32),\n",
        "                np.empty((0,), dtype=np.float32))\n",
        "\n",
        "    # Ensure numeric & drop NaNs in features/targets\n",
        "    num_df = df.copy()\n",
        "    for c in features + [cls_col, reg_col]:\n",
        "        num_df[c] = pd.to_numeric(num_df[c], errors=\"coerce\")\n",
        "    num_df = num_df.dropna(subset=features + [cls_col, reg_col, \"datetime\"])\n",
        "\n",
        "    X_list, y_cls_list, y_sent_list = [], [], []\n",
        "\n",
        "    # Build windows per symbol\n",
        "    for sym, g in num_df.groupby(\"symbol\"):\n",
        "        g = g.sort_values(\"datetime\")\n",
        "        if len(g) <= window:\n",
        "            continue  # not enough history for one sample\n",
        "\n",
        "        vals = g[features].to_numpy(dtype=np.float32, copy=False)\n",
        "        cls  = g[cls_col].to_numpy(dtype=np.float32, copy=False)\n",
        "        reg  = g[reg_col].to_numpy(dtype=np.float32, copy=False)\n",
        "\n",
        "        # Sliding windows: [t-window, t)\n",
        "        for t in range(window, len(g)):\n",
        "            X_list.append(vals[t-window:t, :])\n",
        "            y_cls_list.append(cls[t])\n",
        "            y_sent_list.append(reg[t])   # already shifted upstream → no peek\n",
        "\n",
        "    if not X_list:\n",
        "        F = len(features)\n",
        "        return (np.empty((0, window, F), dtype=np.float32),\n",
        "                np.empty((0,), dtype=np.float32),\n",
        "                np.empty((0,), dtype=np.float32))\n",
        "\n",
        "    X = np.stack(X_list).astype(np.float32)\n",
        "    y_cls = np.asarray(y_cls_list, dtype=np.float32)\n",
        "    y_sent = np.asarray(y_sent_list, dtype=np.float32)\n",
        "    return X, y_cls, y_sent\n"
      ],
      "metadata": {
        "id": "UaVlURPeh1fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"A) Hourly OHLCV…\")\n",
        "ohlcv_hourly = build_hourly_ohlcv(OHLCV_PATH)\n",
        "print(\"   rows:\", len(ohlcv_hourly))\n",
        "\n",
        "print(\"B) Hourly sentiment (fill 0.0 → shift +1h)…\")\n",
        "sent_hourly = build_hourly_sentiment(SENTIMENT_PATHS)\n",
        "print(\"   rows:\", len(sent_hourly))\n",
        "\n",
        "print(\"C) Join features…\")\n",
        "dataset = join_features(ohlcv_hourly, sent_hourly)\n",
        "print(\"   joined rows:\", len(dataset))\n",
        "\n",
        "print(\"D) Label bullish/bearish (4h-ahead)…\")\n",
        "dataset = add_bullish_label(dataset, HORIZON_HOURS)\n",
        "\n",
        "# ---- Save full hourly dataset (robust to 'symbol' vs 'tickr') ----\n",
        "ret_col = f\"future_ret_{HORIZON_HOURS}h\"\n",
        "ret_col_fixed = \"future_ret_4h\" if HORIZON_HOURS == 4 else ret_col\n",
        "\n",
        "keep_candidates = [\n",
        "    \"datetime\",\"symbol\",\"tickr\",\"open\",\"high\",\"low\",\"close\",\"volume\",\n",
        "    \"sentiment_shifted\",\"future_close\", ret_col_fixed, \"target_updown\"\n",
        "]\n",
        "keep_cols = [c for c in keep_candidates if c in dataset.columns]\n",
        "hourly_out = dataset[keep_cols].copy()\n",
        "\n",
        "# pick whichever ID column exists\n",
        "id_col = \"symbol\" if \"symbol\" in hourly_out.columns else (\"tickr\" if \"tickr\" in hourly_out.columns else None)\n",
        "\n",
        "# Sort ONLY by columns that exist\n",
        "sort_cols = [c for c in ([id_col, \"datetime\"] if id_col else [\"datetime\"]) if c in hourly_out.columns]\n",
        "if sort_cols:\n",
        "    hourly_out = hourly_out.sort_values(sort_cols)\n",
        "\n",
        "# (optional) standardize id col in the saved CSV to 'symbol'\n",
        "if id_col == \"tickr\":\n",
        "    hourly_out = hourly_out.rename(columns={\"tickr\": \"symbol\"})\n",
        "\n",
        "out_csv = OUT_DIR / \"full_hourly_dataset.csv\"\n",
        "hourly_out.to_csv(out_csv, index=False)\n",
        "print(\"Saved full hourly dataset:\", out_csv)\n",
        "print(\"  Rows:\", len(hourly_out))\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "# ===== Window-building pipeline =====\n",
        "if dataset.empty:\n",
        "    print(\"No rows to window after labeling. Stop here.\")\n",
        "else:\n",
        "    # Standardize in-memory dataset id col so make_windows (groupby('symbol')) works\n",
        "    if \"symbol\" not in dataset.columns and \"tickr\" in dataset.columns:\n",
        "        dataset = dataset.rename(columns={\"tickr\": \"symbol\"})\n",
        "\n",
        "    print(\"E) Keep rows with all features…\")\n",
        "    needed = list(dict.fromkeys(FEATURE_COLS + [\"target_updown\", \"sentiment_shifted\"]))\n",
        "    dataset = dataset.dropna(subset=needed)\n",
        "\n",
        "    print(\"F) Make 48-step windows with dual targets…\")\n",
        "    X, y_cls, y_sent = make_windows(\n",
        "        dataset, WINDOW, FEATURE_COLS,\n",
        "        cls_col=\"target_updown\",\n",
        "        reg_col=\"sentiment_shifted\"\n",
        "    )\n",
        "\n",
        "    print(\"G) Save arrays + preview…\")\n",
        "    np.save(OUT_DIR/\"X.npy\", X)\n",
        "    np.save(OUT_DIR/\"y_cls.npy\", y_cls)     # 1=Bullish, 0=Bearish\n",
        "    np.save(OUT_DIR/\"y_sent.npy\", y_sent)   # regression: sentiment score\n",
        "\n",
        "    dataset.tail(10).to_csv(OUT_DIR/\"preview_last10.csv\", index=False)\n",
        "    meta = {\n",
        "        \"features\": FEATURE_COLS,\n",
        "        \"window\": WINDOW,\n",
        "        \"horizon_hours_for_label\": HORIZON_HOURS,\n",
        "        \"X_shape\": list(X.shape),\n",
        "        \"y_cls_shape\": list(y_cls.shape),\n",
        "        \"y_sent_shape\": list(y_sent.shape),\n",
        "        \"saved_dir\": str(OUT_DIR),\n",
        "    }\n",
        "    import json\n",
        "    with open(OUT_DIR/\"meta.json\", \"w\") as f:\n",
        "        json.dump(meta, f, indent=2)\n",
        "\n",
        "    print(\"Done. Saved to:\", OUT_DIR)\n",
        "    print(\"Shapes:\", meta)\n"
      ],
      "metadata": {
        "id": "E5lV9M5sh3zH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir -p \"/content/drive/My Drive/lstm_ready\"\n",
        "!cp -v /content/lstm_ready/full_hourly_dataset.csv \"/content/drive/My Drive/lstm_ready/\"\n",
        "\n"
      ],
      "metadata": {
        "id": "qRGGA5R2h9ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLORATORY DATA ANALYSIS\n"
      ],
      "metadata": {
        "id": "arQSItSViUBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Class distribution (Bullish Vs Bearish)\n",
        "y_cls = np.load(\"/content/lstm_ready/y_cls.npy\")  # 0=Bearish, 1=Bullish\n",
        "\n",
        "counts = {0: int((y_cls==0).sum()), 1: int((y_cls==1).sum())}\n",
        "total  = len(y_cls)\n",
        "perc0  = 100.0 * counts[0] / total if total else 0.0\n",
        "perc1  = 100.0 * counts[1] / total if total else 0.0\n",
        "\n",
        "print(\"Class counts (windowed samples):\")\n",
        "print({\"Bearish (0)\": counts[0], \"Bullish (1)\": counts[1]})\n",
        "print(\"\\nClass percentages (windowed samples):\")\n",
        "print({\"Bearish (0)\": round(perc0,2), \"Bullish (1)\": round(perc1,2)})\n",
        "\n",
        "# Optional: bar chart\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.bar([\"Bearish (0)\", \"Bullish (1)\"], [counts[0], counts[1]])\n",
        "plt.title(\"Class Distribution (Windowed Samples)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1afrTmdzh-RK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing or null Values\n",
        "\n",
        "\n",
        "CSV_PATH = \"/content/lstm_ready/full_hourly_dataset.csv\"\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# 1) Per-column null counts and percentages\n",
        "null_counts = df.isna().sum().sort_values(ascending=False)\n",
        "null_pct = (df.isna().mean()*100).round(2).sort_values(ascending=False)\n",
        "summary = pd.DataFrame({\"null_count\": null_counts, \"null_%\": null_pct})\n",
        "print(\"Nulls by column:\")\n",
        "print(summary)\n",
        "\n",
        "# 2) Rows that contain ANY null\n",
        "rows_with_any_null = df.isna().any(axis=1).sum()\n",
        "print(\"\\nRows with ANY null:\", rows_with_any_null, \"out of\", len(df))\n",
        "\n",
        "# 3) Peek at a few problematic rows (if any)\n",
        "if rows_with_any_null:\n",
        "    print(\"\\nSample rows with nulls:\")\n",
        "    display(df[df.isna().any(axis=1)].head(10))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vVbga_UKiEi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for outliers\n",
        "\n",
        "# ---- keep only feature columns (drop targets & non-features) ----\n",
        "drop_cols = [c for c in [\"target_updown\", \"future_ret_4h\", \"future_close\", \"datetime\", \"symbol\"] if c in df.columns]\n",
        "feat_df = df.drop(columns=drop_cols, errors=\"ignore\").select_dtypes(include=[np.number])\n",
        "\n",
        "print(\"Feature columns:\", list(feat_df.columns))\n",
        "\n",
        "# ---- Outlier summary by IQR rule (per column) ----\n",
        "rows = []\n",
        "for col in feat_df.columns:\n",
        "    s = feat_df[col].dropna()\n",
        "    q1 = s.quantile(0.25); q3 = s.quantile(0.75); iqr = q3 - q1\n",
        "    lo = q1 - 1.5 * iqr; hi = q3 + 1.5 * iqr\n",
        "    n_out = int(((s < lo) | (s > hi)).sum())\n",
        "    rows.append({\n",
        "        \"feature\": col,\n",
        "        \"q1\": q1, \"q3\": q3, \"iqr\": iqr,\n",
        "        \"lower_bound\": lo, \"upper_bound\": hi,\n",
        "        \"outliers\": n_out,\n",
        "        \"outlier_%\": 100.0 * n_out / max(len(s), 1)\n",
        "    })\n",
        "\n",
        "outlier_summary = pd.DataFrame(rows).sort_values(\"outlier_%\", ascending=False)\n",
        "print(\"\\nOutlier summary (IQR rule):\")\n",
        "print(outlier_summary.to_string(index=False))\n",
        "\n",
        "# Rows containing ANY outlier across features (for inspection)\n",
        "any_outlier_mask = pd.Series(False, index=feat_df.index)\n",
        "for col in feat_df.columns:\n",
        "    s = feat_df[col]\n",
        "    q1 = s.quantile(0.25); q3 = s.quantile(0.75); iqr = q3 - q1\n",
        "    lo = q1 - 1.5 * iqr; hi = q3 + 1.5 * iqr\n",
        "    any_outlier_mask |= (s < lo) | (s > hi)\n",
        "\n",
        "print(\"\\nRows with ANY outlier across features:\", int(any_outlier_mask.sum()), \"of\", len(feat_df))\n",
        "\n",
        "# ---- Box plots (one per feature) ----\n",
        "n = len(feat_df.columns)\n",
        "fig, axes = plt.subplots(nrows=n, ncols=1, figsize=(8, 3*n))\n",
        "if n == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for ax, col in zip(axes, feat_df.columns):\n",
        "    ax.boxplot(feat_df[col].dropna(), vert=True, labels=[col], showfliers=True)\n",
        "    ax.set_title(f\"Box plot: {col}\")\n",
        "    # Optional: log-scale for heavy-tailed columns like volume\n",
        "    if col.lower() == \"volume\":\n",
        "        ax.set_yscale(\"log\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jEWpO_-4iG7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute correlation Matrix\n",
        "\n",
        "drop_cols = [\"datetime\", \"symbol\", \"target_updown\", \"future_ret_4h\", \"future_close\"]\n",
        "feat_df = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n",
        "\n",
        "\n",
        "\n",
        "# Ensure numeric + handle NaNs/Infs\n",
        "feat_df = feat_df.select_dtypes(include=[np.number]).replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# Pearson correlation\n",
        "corr = feat_df.corr(method=\"pearson\")\n",
        "\n",
        "print(\"Correlation matrix (rounded):\")\n",
        "print(corr.round(3))\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 6))\n",
        "im = ax.imshow(corr.values, vmin=-1, vmax=1)\n",
        "\n",
        "# Tick labels\n",
        "ax.set_xticks(range(len(corr.columns)))\n",
        "ax.set_yticks(range(len(corr.columns)))\n",
        "ax.set_xticklabels(corr.columns, rotation=45, ha=\"right\")\n",
        "ax.set_yticklabels(corr.columns)\n",
        "\n",
        "# Colorbar\n",
        "cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "cbar.set_label(\"Pearson r\")\n",
        "\n",
        "ax.set_title(\"Feature Correlation Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G7iDkYr4iJKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "open, high, low, close are closely correlated with target. Volume has weak positive correlation. Sentiment score has almost zero correlation when compared to others that means it is independent of price or volume."
      ],
      "metadata": {
        "id": "s84vA3XLiRyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "\n",
        "    torch.manual_seed(seed)      # Set PyTorch's random seed\n",
        "    np.random.seed(seed)         # Set NumPy's random seed\n",
        "\n",
        "# Make CUDA (GPU) operations deterministic to ensure repeatable results\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Apply the seed value (commonly used default)\n",
        "set_seed(42)\n"
      ],
      "metadata": {
        "id": "9URI43zc9oXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This selects the compute device: use GPU ('cuda') if available,\n",
        "# otherwise fall back to CPU. This ensures compatibility on all systems.\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "ZTWeXT569snL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def run_epoch(\n",
        "    model, optimizer, data_loader, loss_func, device, results,\n",
        "    score_funcs=None, prefix=\"\", desc=None,\n",
        "    task_type=\"classification\"  # \"classification\" or \"regression\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Runs one full epoch (training or evaluation).\n",
        "\n",
        "    Args:\n",
        "        model: torch.nn.Module\n",
        "        optimizer: torch.optim.Optimizer\n",
        "        data_loader: DataLoader\n",
        "        loss_func: torch.nn loss function\n",
        "        device: torch.device\n",
        "        results: dict to store metrics across epochs\n",
        "        score_funcs: dict of metric functions {name: func(y_true, y_pred)}\n",
        "        prefix: str, prefix for metric keys (\"train\" or \"val\")\n",
        "        desc: str, description for tqdm progress bar\n",
        "        task_type: str, \"classification\" or \"regression\"\n",
        "    \"\"\"\n",
        "    if score_funcs is None:\n",
        "        score_funcs = {}\n",
        "\n",
        "    running_loss = []\n",
        "    y_true_all = []\n",
        "    y_pred_all = []\n",
        "    start = time.time()\n",
        "\n",
        "    for inputs, labels in tqdm(data_loader, desc=desc, leave=False):\n",
        "        # Move to device\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Reset gradients before forward pass\n",
        "        if model.training:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_func(outputs, labels)\n",
        "\n",
        "        # Backward + optimize (training mode only)\n",
        "        if model.training:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Record loss\n",
        "        running_loss.append(loss.item())\n",
        "\n",
        "        # Collect preds for metrics\n",
        "        if len(score_funcs) > 0:\n",
        "            if task_type == \"classification\":\n",
        "                # Multi-class vs binary\n",
        "                if outputs.shape[1] > 1:\n",
        "                    preds = torch.softmax(outputs, dim=1).detach().cpu().numpy()\n",
        "                    preds = np.argmax(preds, axis=1)\n",
        "                    labels_np = labels.detach().cpu().numpy()\n",
        "                else:\n",
        "                    preds = torch.sigmoid(outputs).detach().cpu().numpy()\n",
        "                    preds = (preds >= 0.5).astype(int)  # threshold default\n",
        "                    labels_np = labels.detach().cpu().numpy()\n",
        "            else:  # regression\n",
        "                preds = outputs.detach().cpu().numpy()\n",
        "                labels_np = labels.detach().cpu().numpy()\n",
        "\n",
        "            y_true_all.extend(labels_np.tolist())\n",
        "            y_pred_all.extend(preds.tolist())\n",
        "\n",
        "    # End time\n",
        "    end = time.time()\n",
        "\n",
        "    # Store average loss\n",
        "    results[prefix + \" loss\"].append(np.mean(running_loss))\n",
        "\n",
        "    # Store metrics\n",
        "    for name, score_func in score_funcs.items():\n",
        "        try:\n",
        "            results[prefix + \" \" + name].append(score_func(y_true_all, y_pred_all))\n",
        "        except Exception:\n",
        "            results[prefix + \" \" + name].append(float(\"NaN\"))\n",
        "\n",
        "    return end - start\n"
      ],
      "metadata": {
        "id": "jbdz_5xL-8bY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_network(\n",
        "    model, loss_func, train_loader, val_loader=None, test_loader=None,\n",
        "    score_funcs=None, epochs=50, device=\"cpu\", checkpoint_file=None,\n",
        "    lr_schedule=None, optimizer=None, disable_tqdm=False, task_type=\"classification\"\n",
        "):\n",
        "    import pandas as pd\n",
        "    import torch\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    score_funcs = score_funcs or {}\n",
        "\n",
        "    # Track metrics\n",
        "    to_track = [\"epoch\", \"total time\", \"train loss\"]\n",
        "    if val_loader:  to_track.append(\"val loss\")\n",
        "    if test_loader: to_track.append(\"test loss\")\n",
        "\n",
        "    for metric in score_funcs:\n",
        "        to_track.append(\"train \" + metric)\n",
        "        if val_loader: to_track.append(\"val \" + metric)\n",
        "        if test_loader: to_track.append(\"test \" + metric)\n",
        "\n",
        "    results = {key: [] for key in to_track}\n",
        "    total_train_time = 0\n",
        "\n",
        "    # Optimizer default\n",
        "    if optimizer is None:\n",
        "        optimizer = torch.optim.AdamW(model.parameters())\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in tqdm(range(epochs), desc=\"Epoch\", disable=disable_tqdm):\n",
        "        # Training\n",
        "        model.train()\n",
        "        total_train_time += run_epoch(\n",
        "            model, optimizer, train_loader, loss_func,\n",
        "            device, results, score_funcs, prefix=\"train\",\n",
        "            desc=f\"Training (Epoch {epoch+1})\", task_type=task_type\n",
        "        )\n",
        "\n",
        "        results[\"epoch\"].append(epoch)\n",
        "        results[\"total time\"].append(total_train_time)\n",
        "\n",
        "        # Validation\n",
        "        if val_loader:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                run_epoch(\n",
        "                    model, optimizer, val_loader, loss_func,\n",
        "                    device, results, score_funcs, prefix=\"val\",\n",
        "                    desc=f\"Validating (Epoch {epoch+1})\", task_type=task_type\n",
        "                )\n",
        "\n",
        "        # LR scheduler\n",
        "        if lr_schedule:\n",
        "            if isinstance(lr_schedule, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
        "                lr_schedule.step(results[\"val loss\"][-1])\n",
        "            else:\n",
        "                lr_schedule.step()\n",
        "\n",
        "        # Testing\n",
        "        if test_loader:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                run_epoch(\n",
        "                    model, optimizer, test_loader, loss_func,\n",
        "                    device, results, score_funcs, prefix=\"test\",\n",
        "                    desc=f\"Testing (Epoch {epoch+1})\", task_type=task_type\n",
        "                )\n",
        "\n",
        "        # Save checkpoint\n",
        "        if checkpoint_file:\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'results': results\n",
        "            }, checkpoint_file)\n",
        "\n",
        "    return pd.DataFrame.from_dict(results)\n"
      ],
      "metadata": {
        "id": "QD1anNeY_Osi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Read the CSV file\n",
        "dff = pd.read_csv('/content/drive/MyDrive/full_hourly_dataset.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "M0u5CXvt_9Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# 1) pick features + label\n",
        "FEATURE_COLS = [c for c in [\"close\", \"volume\", \"sentiment_shifted\"] if c in dff.columns]\n",
        "if not FEATURE_COLS:  # fallback: all numeric except obvious non-features\n",
        "    drop_cols = {\"future_return_4h\", \"target_updown\", \"datetime\", \"symbol\", \"tickr\"}\n",
        "    FEATURE_COLS = [c for c in dff.select_dtypes(include=[np.number]).columns if c not in drop_cols]\n",
        "\n",
        "# label: prefer explicit target if present, else derive from future_return_4h\n",
        "if \"target_updown\" in dff.columns:\n",
        "    label = dff[\"target_updown\"].astype(int).to_numpy()\n",
        "else:\n",
        "    assert \"future_return_4h\" in dff.columns, \"Need target_updown or future_return_4h\"\n",
        "    label = (dff[\"future_return_4h\"].to_numpy() > 0).astype(int)\n",
        "\n",
        "features = dff[FEATURE_COLS].to_numpy(dtype=np.float32)\n",
        "\n",
        "# 2) robust scale the entire feature matrix\n",
        "scaler = RobustScaler()\n",
        "features_scaled = scaler.fit_transform(features).astype(np.float32)\n",
        "\n",
        "# 3) train/test split (stratified)\n",
        "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.20, random_state=42)\n",
        "(train_index, test_index), = splitter.split(features_scaled, label)\n",
        "\n",
        "X_train_full, X_test = features_scaled[train_index], features_scaled[test_index]\n",
        "y_train_full, y_test  = label[train_index], label[test_index]\n",
        "\n",
        "# 4) train/val split (stratified) from the training fold\n",
        "val_splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.20, random_state=42)\n",
        "(train_idx, val_idx), = val_splitter.split(X_train_full, y_train_full)\n",
        "\n",
        "X_train, y_train = X_train_full[train_idx], y_train_full[train_idx]\n",
        "X_val,   y_val   = X_train_full[val_idx],  y_train_full[val_idx]\n",
        "\n",
        "# 5)  shapes + class distributions\n",
        "print(\"Shapes  | X_train:\", X_train.shape, \"| X_val:\", X_val.shape, \"| X_test:\", X_test.shape)\n",
        "print(\"Features used:\", FEATURE_COLS)\n",
        "print(\"Train class distribution:\", Counter(y_train))\n",
        "print(\"Val   class distribution:\", Counter(y_val))\n",
        "print(\"Test  class distribution:\", Counter(y_test))\n"
      ],
      "metadata": {
        "id": "3og8NFe3BmXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# Compat: if you used *_final names, map them back\n",
        "if 'X_train' not in globals() and 'X_train_final' in globals():\n",
        "    X_train, y_train = X_train_final, y_train_final\n",
        "    X_val,   y_val   = X_val_final,   y_val_final\n",
        "\n",
        "# Convert to tensors\n",
        "features_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "features_val_tensor   = torch.tensor(X_val,   dtype=torch.float32)\n",
        "features_test_tensor  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "\n",
        "labels_train_tensor = torch.tensor(np.asarray(y_train), dtype=torch.long)\n",
        "labels_val_tensor   = torch.tensor(np.asarray(y_val),   dtype=torch.long)\n",
        "labels_test_tensor  = torch.tensor(np.asarray(y_test),  dtype=torch.long)\n",
        "\n",
        "# Wrap in TensorDatasets\n",
        "train_dataset = TensorDataset(features_train_tensor, labels_train_tensor)\n",
        "val_dataset   = TensorDataset(features_val_tensor,   labels_val_tensor)\n",
        "test_dataset  = TensorDataset(features_test_tensor,  labels_test_tensor)\n",
        "\n",
        "# Sizes\n",
        "print(\"Train set size:\", len(train_dataset))\n",
        "print(\"Validation set size:\", len(val_dataset))\n",
        "print(\"Test set size:\", len(test_dataset))\n"
      ],
      "metadata": {
        "id": "Qtsoftv3CyN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch sizes + DataLoaders\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "# Batch sizes\n",
        "train_batch_size = 32\n",
        "val_batch_size   = 32\n",
        "test_batch_size  = 16\n",
        "\n",
        "# GPU-friendly loader kwargs\n",
        "loader_kwargs = {\"num_workers\": 2, \"pin_memory\": True} if torch.cuda.is_available() else {}\n",
        "\n",
        "# DataLoaders (assumes you already created train_dataset, val_dataset, test_dataset)\n",
        "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True,  **loader_kwargs)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=val_batch_size,   shuffle=False, **loader_kwargs)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=test_batch_size,  shuffle=False, **loader_kwargs)\n",
        "\n",
        "# quick sanity check\n",
        "for name, dl in [(\"train\", train_loader), (\"val\", val_loader), (\"test\", test_loader)]:\n",
        "    try:\n",
        "        xb, yb = next(iter(dl))\n",
        "        print(f\"{name}: batch {tuple(xb.shape)} labels {tuple(yb.shape)}\")\n",
        "    except StopIteration:\n",
        "        print(f\"{name}: dataset is empty 🤷\")\n"
      ],
      "metadata": {
        "id": "cYFik-N2DNXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Multitask LSTM training from `dff` (chronological split, train-only scaling, sequence windows) =====\n",
        "# - Pulls features/labels from your DataFrame `dff`\n",
        "# - Builds [B,T,F] windows for LSTM\n",
        "# - Handles class imbalance (WeightedRandomSampler + class-weighted Focal Loss)\n",
        "# - Monitors PR-AUC; chooses a balanced threshold from validation each epoch\n",
        "# =========================================================================================================\n",
        "\n",
        "import math, numpy as np, torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import (accuracy_score, balanced_accuracy_score, f1_score,\n",
        "                             precision_score, recall_score, roc_auc_score,\n",
        "                             mean_squared_error, mean_absolute_error,\n",
        "                             roc_curve, precision_recall_curve, average_precision_score)\n",
        "\n",
        "# Reproducibility\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "set_seed(42)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#  Config\n",
        "T_WINDOW   = 48     # timesteps per window\n",
        "HORIZON    = 0      # label offset from the last step (0 = label at last step)\n",
        "VAL_FRACT  = 0.15   # 15% validation (chronological)\n",
        "TEST_FRACT = 0.15   # 15% test (chronological)\n",
        "BATCH_TR   = 256\n",
        "BATCH_EVAL = 256\n",
        "LR         = 1e-3\n",
        "WD         = 1e-4\n",
        "HIDDEN     = 96\n",
        "LAYERS     = 2\n",
        "DROPOUT    = 0.1\n",
        "ALPHA_CLS  = 1.0    # weight for classification loss\n",
        "BETA_REG   = 0.5    # weight for regression loss\n",
        "EPOCHS     = 20\n",
        "\n",
        "#  1) Pull data from your `dff`\n",
        "assert \"dff\" in globals(), \"Expected a pandas DataFrame `dff` in memory.\"\n",
        "\n",
        "# Sort chronologically to avoid leakage\n",
        "for time_col in [\"datetime\", \"timestamp\", \"date\", \"time\"]:\n",
        "    if time_col in dff.columns:\n",
        "        dff = dff.sort_values(time_col).reset_index(drop=True)\n",
        "        break  # use the first time-like column found\n",
        "\n",
        "# Choose feature columns\n",
        "FEATURE_COLS = [c for c in [\"close\", \"volume\", \"sentiment_shifted\"] if c in dff.columns]\n",
        "if not FEATURE_COLS:\n",
        "    # fallback: all numeric except obvious label/ID columns\n",
        "    drop_cols = {\"future_return_4h\", \"target_updown\", \"symbol\", \"tickr\", \"id\"}\n",
        "    FEATURE_COLS = [c for c in dff.select_dtypes(include=[np.number]).columns if c not in drop_cols]\n",
        "\n",
        "# Classification label\n",
        "if \"target_updown\" in dff.columns:\n",
        "    y_cls_all = dff[\"target_updown\"].astype(np.int64).to_numpy()\n",
        "else:\n",
        "    assert \"future_return_4h\" in dff.columns, \"Need `target_updown` or `future_return_4h` in `dff`.\"\n",
        "    y_cls_all = (dff[\"future_return_4h\"].to_numpy() > 0).astype(np.int64)\n",
        "\n",
        "# Regression target\n",
        "if \"sentiment_shifted\" in dff.columns:\n",
        "    y_reg_all = dff[\"sentiment_shifted\"].astype(np.float32).to_numpy()\n",
        "else:\n",
        "    y_reg_all = dff[\"future_return_4h\"].astype(np.float32).to_numpy()\n",
        "\n",
        "X_all = dff[FEATURE_COLS].astype(np.float32).to_numpy()\n",
        "\n",
        "# Drop rows with NaNs/Infs (keeps alignment)\n",
        "mask = np.isfinite(X_all).all(1) & np.isfinite(y_cls_all) & np.isfinite(y_reg_all)\n",
        "X_all, y_cls_all, y_reg_all = X_all[mask], y_cls_all[mask], y_reg_all[mask]\n",
        "N = len(X_all)\n",
        "assert N > (T_WINDOW + HORIZON + 10), \"Not enough rows for windowing—reduce T_WINDOW or HORIZON.\"\n",
        "\n",
        "#  2) Chronological split (train / val / test)\n",
        "i_test = int(N * (1 - TEST_FRACT))\n",
        "i_val  = int(i_test * (1 - VAL_FRACT))  # val is a fraction of (train+val)\n",
        "# splits: [0 : i_val) -> train, [i_val : i_test) -> val, [i_test : N) -> test\n",
        "X_train_raw, y_train_cls_raw, y_train_reg_raw = X_all[:i_val],  y_cls_all[:i_val],  y_reg_all[:i_val]\n",
        "X_val_raw,   y_val_cls_raw,   y_val_reg_raw   = X_all[i_val:i_test], y_cls_all[i_val:i_test], y_reg_all[i_val:i_test]\n",
        "X_test_raw,  y_test_cls_raw,  y_test_reg_raw  = X_all[i_test:], y_cls_all[i_test:], y_reg_all[i_test:]\n",
        "\n",
        "print(f\"Chrono splits → train: {len(X_train_raw)}, val: {len(X_val_raw)}, test: {len(X_test_raw)}\")\n",
        "\n",
        "#  3) Scale on TRAIN only\n",
        "scaler = RobustScaler()\n",
        "scaler.fit(X_train_raw)\n",
        "X_train = scaler.transform(X_train_raw).astype(np.float32)\n",
        "X_val   = scaler.transform(X_val_raw).astype(np.float32)\n",
        "X_test  = scaler.transform(X_test_raw).astype(np.float32)\n",
        "\n",
        "#  4) Build [B,T,F] windows per split\n",
        "def make_windows(X, yc, yr, T=48, horizon=0):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      Xw:  [M, T, F]\n",
        "      ycw: [M]\n",
        "      yrw: [M]\n",
        "    Uses label at index (start+T-1+horizon).\n",
        "    \"\"\"\n",
        "    M = len(X) - T - horizon + 1\n",
        "    if M <= 0:\n",
        "        return np.empty((0, T, X.shape[1]), np.float32), np.empty((0,), np.int64), np.empty((0,), np.float32)\n",
        "    Xw  = np.zeros((M, T, X.shape[1]), dtype=np.float32)\n",
        "    ycw = np.zeros((M,), dtype=np.int64)\n",
        "    yrw = np.zeros((M,), dtype=np.float32)\n",
        "    for i in range(M):\n",
        "        start = i\n",
        "        end   = i + T\n",
        "        tgt_i = end - 1 + horizon\n",
        "        Xw[i]  = X[start:end]\n",
        "        ycw[i] = int(yc[tgt_i])\n",
        "        yrw[i] = float(yr[tgt_i])\n",
        "    return Xw, ycw, yrw\n",
        "\n",
        "Xtr, ytr_cls, ytr_reg = make_windows(X_train, y_train_cls_raw, y_train_reg_raw, T=T_WINDOW, horizon=HORIZON)\n",
        "Xva, yva_cls, yva_reg = make_windows(X_val,   y_val_cls_raw,   y_val_reg_raw,   T=T_WINDOW, horizon=HORIZON)\n",
        "Xte, yte_cls, yte_reg = make_windows(X_test,  y_test_cls_raw,  y_test_reg_raw,  T=T_WINDOW, horizon=HORIZON)\n",
        "\n",
        "print(\"Windowed shapes →\",\n",
        "      f\"Xtr {Xtr.shape}, Xva {Xva.shape}, Xte {Xte.shape}\")\n",
        "\n",
        "# Class balance (train)\n",
        "from collections import Counter\n",
        "print(\"Train class distribution:\", Counter(ytr_cls))\n",
        "print(\"Val   class distribution:\", Counter(yva_cls))\n",
        "print(\"Test  class distribution:\", Counter(yte_cls))\n",
        "\n",
        "#  5) Tensors & Datasets\n",
        "Xtr_t  = torch.tensor(Xtr,  dtype=torch.float32)\n",
        "Xva_t  = torch.tensor(Xva,  dtype=torch.float32)\n",
        "Xte_t  = torch.tensor(Xte,  dtype=torch.float32)\n",
        "ytrc_t = torch.tensor(ytr_cls, dtype=torch.long)\n",
        "yvac_t = torch.tensor(yva_cls, dtype=torch.long)\n",
        "ytec_t = torch.tensor(yte_cls, dtype=torch.long)\n",
        "ytrr_t = torch.tensor(ytr_reg, dtype=torch.float32)\n",
        "yvar_t = torch.tensor(yva_reg, dtype=torch.float32)\n",
        "yter_t = torch.tensor(yte_reg, dtype=torch.float32)\n",
        "\n",
        "train_ds = TensorDataset(Xtr_t, ytrc_t, ytrr_t)\n",
        "val_ds   = TensorDataset(Xva_t, yvac_t, yvar_t)\n",
        "test_ds  = TensorDataset(Xte_t, ytec_t, yter_t)\n",
        "\n",
        "#  6) Train-only balancing via WeightedRandomSampler\n",
        "class_counts = np.bincount(ytr_cls.astype(int), minlength=2)\n",
        "neg, pos = int(class_counts[0]), int(class_counts[1])\n",
        "\n",
        "w_per_class = np.zeros(2, dtype=np.float32)\n",
        "w_per_class[0] = 1.0 / max(neg, 1)\n",
        "w_per_class[1] = 1.0 / max(pos, 1)\n",
        "sample_weights = torch.tensor(w_per_class[ytr_cls.astype(int)], dtype=torch.float32)\n",
        "sampler = WeightedRandomSampler(weights=sample_weights,\n",
        "                                num_samples=len(sample_weights),\n",
        "                                replacement=True)\n",
        "\n",
        "#  7) DataLoaders\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_TR, sampler=sampler,\n",
        "                          num_workers=2, pin_memory=True, drop_last=False)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_EVAL, shuffle=False,\n",
        "                          num_workers=2, pin_memory=True, drop_last=False)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_EVAL, shuffle=False,\n",
        "                          num_workers=2, pin_memory=True, drop_last=False)\n",
        "\n",
        "#  8) Model\n",
        "class MultiTaskLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden=96, layers=2, dropout=0.1, bidirectional=False):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden, num_layers=layers,\n",
        "                            dropout=dropout if layers > 1 else 0.0,\n",
        "                            batch_first=True, bidirectional=bidirectional)\n",
        "        out_dim = hidden * (2 if bidirectional else 1)\n",
        "        self.cls_head = nn.Linear(out_dim, 2)\n",
        "        self.reg_head = nn.Linear(out_dim, 1)\n",
        "    def forward(self, x):            # x: [B,T,F]\n",
        "        out, _ = self.lstm(x)        # [B,T,H*dirs]\n",
        "        h = out[:, -1, :]            # last step\n",
        "        logits = self.cls_head(h)    # [B,2]\n",
        "        reg    = self.reg_head(h).squeeze(1)  # [B]\n",
        "        return logits, reg\n",
        "\n",
        "model = MultiTaskLSTM(input_size=Xtr.shape[2], hidden=HIDDEN, layers=LAYERS, dropout=DROPOUT,\n",
        "                      bidirectional=False).to(device)\n",
        "\n",
        "# 9) Losses, Optimizer, Scheduler\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=1.5, reduction='mean'):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "    def forward(self, logits, target):\n",
        "        ce = F.cross_entropy(logits, target, weight=self.alpha, reduction='none')\n",
        "        pt = torch.softmax(logits, dim=1).gather(1, target.view(-1,1)).squeeze(1).clamp_min(1e-8)\n",
        "        loss = ((1.0 - pt) ** self.gamma) * ce\n",
        "        return loss.mean() if self.reduction == 'mean' else loss.sum()\n",
        "\n",
        "alpha = torch.tensor([1.0 / max(neg,1), 1.0 / max(pos,1)], dtype=torch.float32, device=device)\n",
        "cls_loss = FocalLoss(alpha=alpha, gamma=1.5).to(device)     # class-weighted focal\n",
        "reg_loss = nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\",\n",
        "                                                       factor=0.5, patience=2, verbose=True)\n",
        "\n",
        "#  10) Helpers: eval + balanced threshold\n",
        "def best_balanced_threshold(y_true, probs):\n",
        "    if len(np.unique(y_true)) < 2:\n",
        "        return 0.5\n",
        "    fpr, tpr, thr = roc_curve(y_true, probs)\n",
        "    tnr = 1.0 - fpr\n",
        "    idx = int(np.argmin(np.abs(tpr - tnr)))\n",
        "    return float(np.clip(thr[idx], 0.05, 0.95))\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(loader, threshold=0.5, want_curves=False):\n",
        "    model.eval()\n",
        "    total, n = 0.0, 0\n",
        "    probs_all, ytrue_all = [], []\n",
        "    rp_all, rt_all = [], []\n",
        "    for xb, yb_cls, yb_reg in loader:\n",
        "        xb, yb_cls, yb_reg = xb.to(device), yb_cls.to(device), yb_reg.to(device)\n",
        "        logits, yhat_r = model(xb)\n",
        "        loss = ALPHA_CLS*cls_loss(logits, yb_cls) + BETA_REG*reg_loss(yhat_r, yb_reg)\n",
        "        total += loss.item() * xb.size(0); n += xb.size(0)\n",
        "        probs_all.append(torch.softmax(logits, dim=1)[:,1].detach().cpu().numpy())\n",
        "        ytrue_all.append(yb_cls.detach().cpu().numpy())\n",
        "        rp_all.append(yhat_r.detach().cpu().numpy())\n",
        "        rt_all.append(yb_reg.detach().cpu().numpy())\n",
        "\n",
        "    avg_loss = total / max(n,1)\n",
        "    probs = np.concatenate(probs_all) if probs_all else np.array([])\n",
        "    ytrue = np.concatenate(ytrue_all).astype(int) if ytrue_all else np.array([], dtype=int)\n",
        "    yhat  = (probs >= threshold).astype(int) if probs.size else np.array([], dtype=int)\n",
        "\n",
        "    if ytrue.size and len(np.unique(ytrue)) == 2:\n",
        "        acc  = accuracy_score(ytrue, yhat)\n",
        "        bacc = balanced_accuracy_score(ytrue, yhat)\n",
        "        f1   = f1_score(ytrue, yhat, zero_division=0)\n",
        "        prec = precision_score(ytrue, yhat, zero_division=0)\n",
        "        rec  = recall_score(ytrue, yhat, zero_division=0)\n",
        "        auc  = roc_auc_score(ytrue, probs)\n",
        "        prec_curve, rec_curve, pr_thr = precision_recall_curve(ytrue, probs)\n",
        "        ap   = average_precision_score(ytrue, probs)\n",
        "    else:\n",
        "        acc = bacc = f1 = prec = rec = auc = ap = float(\"nan\")\n",
        "        prec_curve = rec_curve = pr_thr = np.array([])\n",
        "\n",
        "    rp = np.concatenate(rp_all) if rp_all else np.array([])\n",
        "    rt = np.concatenate(rt_all) if rt_all else np.array([])\n",
        "    rmse = math.sqrt(mean_squared_error(rt, rp)) if rt.size else float(\"nan\")\n",
        "    mae  = mean_absolute_error(rt, rp) if rt.size else float(\"nan\")\n",
        "\n",
        "    out = {\"loss\": avg_loss, \"acc\": acc, \"bacc\": bacc, \"f1\": f1, \"prec\": prec, \"rec\": rec, \"auc\": auc,\n",
        "           \"rmse\": rmse, \"mae\": mae, \"ap\": ap, \"probs\": probs, \"ytrue\": ytrue}\n",
        "    if want_curves:\n",
        "        out.update({\"prec_curve\": prec_curve, \"rec_curve\": rec_curve, \"pr_thr\": pr_thr})\n",
        "    return out\n",
        "\n",
        "def train_one_epoch(loader):\n",
        "    model.train()\n",
        "    total, n = 0.0, 0\n",
        "    for xb, yb_cls, yb_reg in loader:\n",
        "        xb, yb_cls, yb_reg = xb.to(device), yb_cls.to(device), yb_reg.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits, yhat_r = model(xb)\n",
        "        loss = ALPHA_CLS*cls_loss(logits, yb_cls) + BETA_REG*reg_loss(yhat_r, yb_reg)\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        total += loss.item() * xb.size(0); n += xb.size(0)\n",
        "    return total / max(n,1)\n",
        "\n",
        "#  11) Train\n",
        "best_val = float(\"inf\")\n",
        "best_state = None\n",
        "best_thresh = 0.5\n",
        "train_losses, val_losses, val_ap_hist = [], [], []\n",
        "\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    tr_loss = train_one_epoch(train_loader)\n",
        "    va = evaluate(val_loader, threshold=best_thresh, want_curves=True)\n",
        "\n",
        "    # choose a balanced threshold from current val probs\n",
        "    thr_bal = best_balanced_threshold(va[\"ytrue\"], va[\"probs\"])\n",
        "    best_thresh = thr_bal  # for reporting / next epoch\n",
        "\n",
        "    train_losses.append(tr_loss); val_losses.append(va[\"loss\"]); val_ap_hist.append(va[\"ap\"])\n",
        "    scheduler.step(va[\"loss\"])\n",
        "\n",
        "    print(f\"Epoch {ep:02d} | train {tr_loss:.4f} | val {va['loss']:.4f} | \"\n",
        "          f\"val bAcc {va['bacc']:.3f} | val F1 {va['f1']:.3f} | val AUC {va['auc']:.3f} | \"\n",
        "          f\"val PR-AUC {va['ap']:.3f} | (balanced thr → {thr_bal:.2f})\")\n",
        "\n",
        "    if va[\"loss\"] < best_val:\n",
        "        best_val = va[\"loss\"]\n",
        "        best_state = {k: v.detach().cpu().clone() if isinstance(v, torch.Tensor) else v\n",
        "                      for k, v in model.state_dict().items()}\n",
        "\n",
        "# Restore best weights (by val loss)\n",
        "if best_state is not None:\n",
        "    model.load_state_dict(best_state)\n",
        "\n",
        "print(\"\\nTraining finished.\")\n",
        "print(f\"Features used: {FEATURE_COLS}\")\n",
        "print(f\"Final balanced threshold from validation: {best_thresh:.2f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DfJhBj-lE7og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Eval: sweep thresholds; choose by Max TNR with min recall; then test\n",
        "import numpy as np, math, torch, pandas as pd\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, balanced_accuracy_score, f1_score,\n",
        "    precision_score, recall_score, roc_auc_score,\n",
        "    confusion_matrix, classification_report,\n",
        "    mean_squared_error, mean_absolute_error\n",
        ")\n",
        "\n",
        "#  Selection rule & constraint\n",
        "FINAL_RULE = \"tnr_min_rec\"   # options left available: \"tnr_min_rec\", \"youden\", \"bacc\"\n",
        "MIN_REC    = 0.30            # <-- minimum recall (TPR) for class 1 you require (tune this)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.eval()\n",
        "\n",
        "@torch.no_grad()\n",
        "def collect_all(loader):\n",
        "    probs_all, ytrue_all = [], []\n",
        "    r_pred_all, r_true_all = [], []\n",
        "    # Works whether your dataset yields (X, y_cls, y_reg) or (X, y_cls) only\n",
        "    for batch in loader:\n",
        "        xb, yb_cls = batch[0], batch[1]\n",
        "        xb = xb.to(device)\n",
        "        logits, yhat_r = model(xb)\n",
        "        probs_all.append(torch.softmax(logits, dim=1)[:, 1].cpu().numpy())\n",
        "        ytrue_all.append(yb_cls.cpu().numpy())\n",
        "        if len(batch) >= 3:\n",
        "            yb_reg = batch[2]\n",
        "            r_pred_all.append(yhat_r.cpu().numpy())\n",
        "            r_true_all.append(yb_reg.cpu().numpy())\n",
        "    probs = np.concatenate(probs_all) if probs_all else np.array([])\n",
        "    ytrue = np.concatenate(ytrue_all).astype(int) if ytrue_all else np.array([], dtype=int)\n",
        "    r_pred = np.concatenate(r_pred_all) if r_pred_all else np.array([])\n",
        "    r_true = np.concatenate(r_true_all) if r_true_all else np.array([])\n",
        "    return probs, ytrue, r_pred, r_true\n",
        "\n",
        "#  1) Sweep thresholds on VALIDATION\n",
        "val_probs, val_true, _, _ = collect_all(val_loader)\n",
        "THRESHOLDS = np.round(np.arange(0.05, 0.96, 0.01), 2)\n",
        "\n",
        "rows = []\n",
        "for th in THRESHOLDS:\n",
        "    yhat = (val_probs >= th).astype(int)\n",
        "\n",
        "    tp = int(((yhat == 1) & (val_true == 1)).sum())\n",
        "    tn = int(((yhat == 0) & (val_true == 0)).sum())\n",
        "    fp = int(((yhat == 1) & (val_true == 0)).sum())   # bears → bulls (false positives)\n",
        "    fn = int(((yhat == 0) & (val_true == 1)).sum())\n",
        "\n",
        "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "    rec  = tp / (tp + fn) if (tp + fn) > 0 else 0.0   # TPR (recall for bulls)\n",
        "    tnr  = tn / (tn + fp) if (tn + fp) > 0 else 0.0   # specificity (for bears)\n",
        "    bacc = (rec + tnr) / 2.0\n",
        "    acc  = (tp + tn) / max(len(val_true), 1)\n",
        "    f1   = (2*prec*rec / (prec + rec)) if (prec + rec) > 0 else 0.0\n",
        "    youden = rec + tnr - 1.0\n",
        "\n",
        "    rows.append({\n",
        "        \"threshold\": th,\n",
        "        \"acc\": acc, \"bacc\": bacc, \"youden\": youden,\n",
        "        \"prec\": prec, \"rec\": rec, \"tnr\": tnr, \"f1\": f1,\n",
        "        \"tp\": tp, \"tn\": tn, \"fp\": fp, \"fn\": fn\n",
        "    })\n",
        "\n",
        "sweep_df = pd.DataFrame(rows)\n",
        "\n",
        "#  Best thresholds by rules\n",
        "best_th_bacc   = float(sweep_df.sort_values([\"bacc\",\"youden\"], ascending=False).iloc[0][\"threshold\"])\n",
        "best_th_youden = float(sweep_df.sort_values([\"youden\",\"bacc\"], ascending=False).iloc[0][\"threshold\"])\n",
        "\n",
        "# Maximize TNR subject to a minimum recall constraint\n",
        "cand = sweep_df[sweep_df[\"rec\"] >= MIN_REC].sort_values([\"tnr\",\"bacc\",\"youden\",\"prec\"], ascending=False)\n",
        "if not cand.empty:\n",
        "    best_th_tnr_minrec = float(cand.iloc[0][\"threshold\"])\n",
        "else:\n",
        "    # if no threshold meets MIN_REC, fall back to pure TNR max\n",
        "    best_th_tnr_minrec = float(sweep_df.sort_values([\"tnr\",\"bacc\",\"youden\",\"prec\"], ascending=False).iloc[0][\"threshold\"])\n",
        "\n",
        "print(\"Best thresholds found on validation:\")\n",
        "print(f\"  • Balanced Accuracy (bAcc): {best_th_bacc:.2f}\")\n",
        "print(f\"  • Youden's J              : {best_th_youden:.2f}\")\n",
        "print(f\"  • Max TNR w/ min recall≥{MIN_REC:.2f}: {best_th_tnr_minrec:.2f}\")\n",
        "\n",
        "print(\"\\nTop 5 by Youden's J:\")\n",
        "print(sweep_df.sort_values(\"youden\", ascending=False).head()[[\"threshold\",\"youden\",\"tnr\",\"rec\",\"bacc\",\"prec\"]])\n",
        "\n",
        "print(f\"\\nTop 5 by TNR subject to recall≥{MIN_REC:.2f}:\")\n",
        "show = cand if not cand.empty else sweep_df.sort_values(\"tnr\", ascending=False)\n",
        "print(show.head()[[\"threshold\",\"tnr\",\"rec\",\"bacc\",\"youden\",\"prec\"]])\n",
        "\n",
        "#  Choose the rule to use on TEST\n",
        "if FINAL_RULE == \"tnr_min_rec\":\n",
        "    best_th = best_th_tnr_minrec\n",
        "elif FINAL_RULE == \"youden\":\n",
        "    best_th = best_th_youden\n",
        "elif FINAL_RULE == \"bacc\":\n",
        "    best_th = best_th_bacc\n",
        "else:\n",
        "    raise ValueError(\"FINAL_RULE must be one of: 'tnr_min_rec', 'youden', 'bacc'\")\n",
        "\n",
        "print(f\"\\n Chosen threshold (rule = {FINAL_RULE}): {best_th:.2f}\")\n",
        "\n",
        "#  2) Evaluate on TEST with chosen threshold\n",
        "test_probs, test_true, test_r_pred, test_r_true = collect_all(test_loader)\n",
        "test_hat = (test_probs >= best_th).astype(int)\n",
        "\n",
        "print(f\"\\n Classification report @ threshold {best_th:.2f} (rule = {FINAL_RULE})\")\n",
        "print(classification_report(test_true, test_hat, digits=3))\n",
        "\n",
        "acc  = accuracy_score(test_true, test_hat)\n",
        "bacc = balanced_accuracy_score(test_true, test_hat)\n",
        "f1   = f1_score(test_true, test_hat, zero_division=0)\n",
        "prec = precision_score(test_true, test_hat, zero_division=0)\n",
        "rec  = recall_score(test_true, test_hat, zero_division=0)\n",
        "auc  = roc_auc_score(test_true, test_probs) if len(np.unique(test_true)) == 2 else float(\"nan\")\n",
        "cm   = confusion_matrix(test_true, test_hat)\n",
        "\n",
        "rmse = math.sqrt(mean_squared_error(test_r_true, test_r_pred)) if test_r_true.size else float(\"nan\")\n",
        "mae  = mean_absolute_error(test_r_true, test_r_pred) if test_r_true.size else float(\"nan\")\n",
        "\n",
        "print(\"\\nTest metrics:\")\n",
        "print(f\"Acc {acc:.3f} | bAcc {bacc:.3f} | F1 {f1:.3f} | Prec {prec:.3f} | Rec {rec:.3f} | AUC {auc:.3f}\")\n",
        "print(f\"Regression: RMSE {rmse:.4f} | MAE {mae:.4f}\")\n",
        "print(\"Confusion matrix (rows=true [0,1], cols=pred [0,1]):\\n\", cm)\n"
      ],
      "metadata": {
        "id": "mILrUnu5QPAA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}